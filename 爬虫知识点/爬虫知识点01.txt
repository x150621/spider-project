Introduction
1. 第一章：网络请求
1.1. 1-爬虫前奏
1.2. 2-http协议和chrome浏览器
1.3. 3-urllib库
1.4. 4-requests库
2. 第二章：数据提取
2.1. 1.xpath语法与lxml库
2.2. 2-BeautifulSoup4库
2.3. 3-正则表达式和re模块
3. 第三章：数据存储
3.1. 1-json文件处理
3.2. 2-csv文件处理
3.3. 3-excel文件处理
3.4. 4-MySQL数据库
3.5. 5-MongoDB数据库
4. 第四章：爬虫进阶
4.1. 1-多线程爬虫
4.2. 2-动态网页爬虫
4.3. 3-图形验证码识别
5. 第五章：Scrapy框架
5.1. 1-框架架构
5.2. 2-快速入门
5.3. 3-CrawlSpider
5.4. 4-ScrapyShell
5.5. 5-Request和Response对象
5.6. 6-下载文件和图片
5.7. 7-下载中间件
5.8. 8-settings配置信息
5.9. 9-Scrapy爬虫实战
6. 第六章：Scrapy-Redis分布式组件
6.1. 1-redis数据库介绍
6.2. 2-Scrapy-Redis组件介绍
6.3. 3-搜房网分布式爬虫
Published with GitBook
爬虫教程
爬虫前奏
爬虫的实际例子：
搜索引擎（百度、谷歌、360搜索等）。
伯乐在线。
惠惠购物助手。
数据分析与研究（数据冰山知乎专栏）。
抢票软件等。
什么是网络爬虫：
通俗理解：爬虫是一个模拟人类请求网站行为的程序。可以自动请求网页、并数据抓取下来，然后使用一定的规则提取有价值的数据。
专业介绍：百度百科。
通用爬虫和聚焦爬虫：
通用爬虫：通用爬虫是搜索引擎抓取系统（百度、谷歌、搜狗等）的重要组成部分。主要是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。
聚焦爬虫：是面向特定需求的一种网络爬虫程序，他与通用爬虫的区别在于：聚焦爬虫在实施网页抓取的时候会对内容进行筛选和处理，尽量保证只抓取与需求相关的网页信息。
为什么用Python写爬虫程序：
PHP：PHP是世界是最好的语言，但他天生不是做这个的，而且对多线程、异步支持不是很好，并发处理能力弱。爬虫是工具性程序，对速度和效率要求比较高。
Java：生态圈很完善，是Python爬虫最大的竞争对手。但是Java语言本身很笨重，代码量很大。重构成本比较高，任何修改会导致代码大量改动。爬虫经常要修改采集代码。
C/C++：运行效率是无敌的。但是学习和开发成本高。写个小爬虫程序可能要大半天时间。
Python：语法优美、代码简洁、开发效率高、支持的模块多。相关的HTTP请求模块和HTML解析模块非常丰富。还有Scrapy和Scrapy-redis框架让我们开发爬虫变得异常简单。
准备工具：
Python3.6开发环境。
Pycharm 2017 professional版。
虚拟环境。`virtualenv/virtualenvwrapper`。